
model_parallel_size = 1
pipe_parallel_size = 0
distributed_backend = "nccl"
DDP_impl = "local" # local / torch
local_rank = None
lazy_mpu_init = False
use_cpu_initialization = False

